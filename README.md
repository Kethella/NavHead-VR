# NavHead-VR
Virtual reality software development project for completion of the bachelor's degree in Computer Science and Media at the Hochschule der Medien - Germany.

## Topic  
**The Impact of Exclusive Head Movements (6DoF) on Navigation Efficiency, Accuracy, and Accessibility for Users with Physical Disabilities in Virtual Environments**  

## Research Question  
**How do exclusive head movements (6DoF) impact navigation efficiency, accuracy, and accessibility for users with physical disabilities in virtual environments?**  

## Technologies Used  
- Unity (3D Project – VR)
- C# (via JetBrains Rider)
- Blender (3D Assets)
- Meta Quest 3 (via Meta Link)

## Summary  

NavHead-VR is a virtual reality experience focused on exploring alternative and accessible interaction methods using **exclusive head movements (6DoF)**. It allows users to interact with a futuristic environment using **face alignment**, **blow-based input (simulated)**, and **keyboard-based toggles** as analog methods to test interaction logic and selection performance.

---

## How to Run the Application

### On Desktop (Developer Mode):

1. Open UnityHub and launch the NavHead-VR project.
2. In Unity, go to: Assets → NavHead → Scenes → MainScene
3. Connect your Meta Quest 3 to the computer using a USB-C cable.
4. On the headset, enable Meta Link when prompted.
5. In the headset’s floating menu, click +, then choose: UnityHub → NavHead MainScene
6. Back in Unity, press Play to enter the VR scene.

> You should now be inside the virtual room with your headset.

---

## Controls & Interaction

- The user starts in a futuristic room.
- Press **`C`** on the keyboard: A cube will appear in front of the user.
- The cube moves according to head movement.
- At the bottom right corner of the view, a selection method indicator is shown:
- STOP = Face Alignment selection (hold alignment for 4 seconds)
- Whistle icon = Blow selection (simulated)
- Press **`L`** to switch between selection modes.
- Press **`S`** to simulate the selection (e.g., blow input).

These modes allow experimental analysis of movement precision and alternative interaction efficiency.

---

## Thesis




